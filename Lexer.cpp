#include <iostream>#include "Lexer.h"#include "ColonAutomaton.h"#include "ColonDashAutomaton.h"#include "PeriodAutomaton.h"#include "AddAutomaton.h"#include "Q_MarkAutomaton.h"#include "MultiplyAutomaton.h"#include "Right_ParenAutomaton.h"#include "Left_ParenAutomaton.h"#include "CommaAutomaton.h"#include "SchemesAutomaton.h"#include "FactsAutomaton.h"#include "RulesAutomaton.h"#include "QueriesAutomaton.h"#include "StringAutomaton.h"#include "IDAutomaton.h"#include "CommentAutomaton.h"#include "BlockCommentAutomaton.h"#include "BadString.h"Lexer::Lexer() {    CreateAutomata();}Lexer::~Lexer() {    for (auto a:automata) {        delete a;    }    for (unsigned int i = 0; i < tokens.size(); i++) {        delete tokens.at(i);    }    //    // TODO: need to clean up the memory in `automata` and `tokens`}void Lexer::CreateAutomata() {    automata.push_back(new ColonAutomaton());    automata.push_back(new ColonDashAutomaton());    automata.push_back(new PeriodAutomaton());    automata.push_back(new AddAutomaton());    automata.push_back(new Q_MarkAutomaton());    automata.push_back(new MultiplyAutomaton());    automata.push_back(new Left_ParenAutomaton());    automata.push_back(new Right_ParenAutomaton());    automata.push_back(new SchemesAutomaton());    automata.push_back(new CommaAutomaton());    automata.push_back(new FactsAutomaton());    automata.push_back(new RulesAutomaton());    automata.push_back(new QueriesAutomaton());    automata.push_back(new StringAutomaton());    automata.push_back(new IDAutomaton());    automata.push_back(new CommentAutomaton());    automata.push_back(new BlockCommentAutomaton());    // automata.push_back(new BadStringAutomaton());    // TODO: Add the other needed automata here}void Lexer::Run(std::string& input) {    // TODO: convert this pseudo-code with the algorithm into actual C++ code    /*    set lineNumber to 1     */    lineNumber = 1;    /*    // While there are more characters to tokenize    loop */    while(input.size() > 0) {        maxRead = 0;        maxAutomaton = automata.at(0);        // TODO: you need to handle whitespace inbetween tokens        if (input.at(0) == '\n') {            lineNumber++;            input.erase (0,1);            continue;        }        else if (isspace(input.at(0)))  {            input.erase (0,1);            continue;        }        // Here is the "Parallel" part of the algorithm        //   Each automaton runs with the same input        for(unsigned int i = 0; i < automata.size(); i++) {            inputRead = automata.at(i)->Start(input);            if (inputRead > maxRead) {                maxRead = inputRead;                maxAutomaton = automata.at(i);            }        }        // Here is the "Max" part of the algorithm        if (maxRead > 0) {            newToken = maxAutomaton->CreateToken(input.substr(0,maxRead), lineNumber);            lineNumber += maxAutomaton->NewLinesRead();            tokens.push_back(newToken);        }        // No automaton accepted input        // Create single character undefined token        else if((int)input.size() == maxRead) {            newToken = new Token(TokenType::UNDEFINED, input.substr(0, maxRead), lineNumber);            tokens.push_back(newToken);        }        else {            maxRead = 1;            newToken = new Token(TokenType::UNDEFINED, std::string(1,input.at(0)), lineNumber);            tokens.push_back(newToken);        }        input.erase (input.begin(),input.begin() + maxRead);    }    /// call end of file automaton    // add end of file token to all tokens    tokens.push_back(new Token(TokenType::EOFile, "", lineNumber));    //  ????    //// Print(tokens);}std::vector<Token*> Lexer::getTokenList () {    return tokens;}void Lexer::Print(std::vector<Token*> tokens) {    for (unsigned int i = 0; i < tokens.size(); i++) {        std::cout << tokens.at(i)->toString();    }    std::cout << "Total Tokens = " << tokens.size();}